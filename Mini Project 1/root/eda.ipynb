{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6289ad5-b0c8-4a0a-8a13-e746cbe37505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a count plot showing the distribution of gender\n",
    "count_plot = sns.countplot(x = 'weekday', data=df)\n",
    "plt.title('Article Count per Weekday')\n",
    "plt.xlabel('Day')  # Label for x-axis\n",
    "plt.ylabel('Count')  # Label for y-axis\n",
    "plt.xticks(rotation = 45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Annotate the bars with the article count value per weekday\n",
    "for p in count_plot.patches:\n",
    "    count_plot.annotate(format(p.get_height(), '.0f'), \n",
    "                        (p.get_x() + p.get_width()/2., \n",
    "                         p.get_height()), \n",
    "                        ha = 'center',  # Horizontal alignment\n",
    "                        va = 'center',  # Vertical alignment\n",
    "                        xytext = (0, 9), \n",
    "                        textcoords = 'offset points')\n",
    "\n",
    "# Replace inconsistent weekday names and verify the count of how many students use each mode of transport\n",
    "df['weekday'].replace({\n",
    "    'moday': 'monday',\n",
    "    'tuesdy': 'tuesday',\n",
    "    'wednsday': 'wednesday',\n",
    "    'thusdy': 'thursday',\n",
    "    'frday': 'friday',\n",
    "    'satday': 'saturday',\n",
    "    'sunda': 'sunday'\n",
    "}, inplace=True).str.capitalize()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a count plot showing the distribution of gender\n",
    "count_plot = sns.countplot(x = 'data_channel', data=df)\n",
    "plt.title('Number of Articles per Channel')\n",
    "plt.xlabel('Data channel')  # Label for x-axis\n",
    "plt.ylabel('Number')  # Label for y-axis\n",
    "plt.xticks(rotation = 45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Annotate the bars with the number of articles per channel\n",
    "for p in count_plot.patches:\n",
    "    count_plot.annotate(format(p.get_height(), '.0f'), \n",
    "                        (p.get_x() + p.get_width()/2., \n",
    "                         p.get_height()), \n",
    "                        ha = 'center',  # Horizontal alignment\n",
    "                        va = 'center',  # Vertical alignment\n",
    "                        xytext = (0, 9), \n",
    "                        textcoords = 'offset points')\n",
    "\n",
    "# Replace inconsistent data_channel names and verify by counting how many students use each mode of transport\n",
    "df['data_channel'].replace({\n",
    "    'entertainment': 'Entertainment',\n",
    "    'business': 'Business',\n",
    "    'technology': 'Technology',\n",
    "    'lifestyle': 'Lifestyle',\n",
    "    'world': 'World',\n",
    "    'social_media': 'Social Media'\n",
    "}, inplace=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fc582-9d29-4bb0-a097-e3544ac6df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram for Target Variable\n",
    "sns.histplot(df['shares'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Article Shares') \n",
    "plt.xlabel('Shares') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()\n",
    "\n",
    "# Histogram for Visual appeal; could influence sharing with the number of images/videos\n",
    "sns.histplot(df['num_imgs'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Distribution of Number of Images in Articles') \n",
    "plt.xlabel('Number of Images') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df['num_imgs'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Distribution of Number of Videos in Articles') \n",
    "plt.xlabel('Number of Videos') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()\n",
    "\n",
    "# Histogram for Internal/External Linking Trends\n",
    "sns.histplot(df['num_hrefs'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Distribution of Hyperlinks in Articles') \n",
    "plt.xlabel('Number of Hyperlink') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df['num_self_hrefs'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Distribution of Self-References in Articles') \n",
    "plt.xlabel('Number of Self-References') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()\n",
    "\n",
    "# Histogram for Article Length\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['n_tokens_content'], bins=10, kde=True) # KDE adds smooth curve\n",
    "plt.title('Distribution of Article Length (in Tokens)') \n",
    "plt.xlabel('Number of Tokens') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75340f81-da67-449c-bf0e-880b0003c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure with a specified size for Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram: Distribution of Shares by Weekday\n",
    "sns.histplot(x = 'shares', hue = 'weekday', kde = True, bins = 18, alpha = 0.6)\n",
    "plt.xscale('log')  # Apply log scale to handle skew\n",
    "plt.title('Distribution of Shares by Weekday')\n",
    "plt.xlabel('Shares')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title = 'Weekday')\n",
    "plt.grid(True) # Enable grid lines for better readability\n",
    "plt.show()\n",
    "\n",
    "# Line Chart: Shares and Comments Over Time (Timely Trends [Timedelta])\n",
    "# Sample 200 random points to avoid clutter\n",
    "df_sample = df.sample(200, random_state=42).sort_values(by='timedelta')\n",
    "\n",
    "# Identify top 10% articles by shares\n",
    "top_shares = df[df['shares'] > df['shares'].quantile(0.90)]\n",
    "\n",
    "# Create a figure with a specified size for Line Chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Shares over Timedelta\n",
    "# plt.plot(df['timedelta'], df['shares'], label = 'Shares', marker = 'x') # Line Plot final test scores with cross markers\n",
    "line1 = sns.lineplot(data=df, x='timedelta', y='shares', label='Shares', marker='x')\n",
    "\n",
    "# Plot Comments over Timedelta\n",
    "# plt.plot(df['timedelta'], df['n_comments'], label = 'Comments', marker = 'o') # Line Plot study hours with circle markers\n",
    "line2 = sns.lineplot(data=df, x='timedelta', y='n_comments', label='Comments', marker='o')\n",
    "\n",
    "# Annotate every 20th Share in Sample\n",
    "for i, (x, y) in enumerate(zip(df_sample['timedelta'], df_sample['shares'])):\n",
    "    if i % 20 == 0:\n",
    "        plt.text(x, y, f'{int(y)}', ha='center', va='bottom', color='orange', fontsize=6)\n",
    "\n",
    "# Annotate every 20th Comment in Sample\n",
    "for i, (x, y) in enumerate(zip(df_sample['timedelta'], df_sample['n_comments'])):\n",
    "    if i % 20 == 0:\n",
    "        plt.text(x, y, f'{int(y)}', ha='center', va='bottom', color='blue', fontsize=6)\n",
    "\n",
    "# Annotate top 10% viral articles with bold highlight\n",
    "for x, y in zip(top_shares['timedelta'], top_shares['shares']):\n",
    "    plt.text(x, y, f'{int(y)}', ha='center', va='bottom', color='violet', fontsize=6, fontweight='bold')\n",
    "\n",
    "plt.title('Shares and Comments Over Timeline (Timedelta)')\n",
    "plt.xlabel('Timedelta')\n",
    "plt.ylabel('Count')\n",
    "plt.legend() # Add legend to distinguish between the two lines\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout() # Adjust subplot parameters for better fit\n",
    "plt.grid(True) # Enable grid lines for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff3072-cb0f-4eb9-bc08-f41b784b2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure with a specified size for a Boxplot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Box plot for Day of Weekday\n",
    "ordered_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "sns.boxplot(x='weekday', y='shares', data=df, order=ordered_days, palette='Set2')\n",
    "plt.title('Which days tend to go viral shares')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Shares')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Box plot for Data Channel\n",
    "sns.boxplot(x='data_channel', y='shares', data=df, palette='Set2')\n",
    "plt.title('Which topics/categories get shared')\n",
    "plt.xlabel('Topics/Categories')\n",
    "plt.ylabel('Shares')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Box plot for Content Length\n",
    "sns.boxplot(x=pd.qcut(df['n_tokens_content'], q=5, labels=['Very Short', 'Short', 'Medium', 'Long', 'Very Long']), y=df['shares'], palette='Set2')\n",
    "plt.title('Shares Distribution Across Article Content Length (Quantile Grouping)')\n",
    "plt.xlabel('n_tokens_content Quantile')\n",
    "plt.ylabel('Shares')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Box plot for Comparison between older and newer articles with timedelta (article age)\n",
    "df_sortedTime = df.sort_values('timedelta')\n",
    "sns.boxplot(x=pd.qcut(df['timedelta'], q=5, labels=['Oldest', 'Older', 'Present', 'Newer', 'Newest']), y=df['shares'], palette='Set2')\n",
    "plt.title('Shares Distribution Across Article Timedelta (Quantile Grouping)')\n",
    "plt.xlabel('timedelta Quantile')\n",
    "plt.ylabel('Shares')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f31e11-bf93-4663-ab9f-b79f8c364095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a 2x2 subplot grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Prepare sorted categories for consistency\n",
    "sorted_day = df['weekday'].value_counts().index\n",
    "sorted_channel = df['data_channel'].value_counts().index\n",
    "\n",
    "# ---------- First Subplot: Article Count per Weekday----------\n",
    "sns.countplot(y='weekday', data=df, order=sorted_day, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Article Count per Weekday')\n",
    "axes[0, 0].set_xlabel('Count')\n",
    "axes[0, 0].set_ylabel('Day of Week')\n",
    "\n",
    "# Annotate bars\n",
    "for p in axes[0, 0].patches:\n",
    "    axes[0, 0].annotate(format(p.get_width(), '.0f'),\n",
    "                        (p.get_width(), p.get_y() + p.get_height() / 2),\n",
    "                        ha='left', va='center',\n",
    "                        xytext=(5, 0),\n",
    "                        textcoords='offset points')\n",
    "\n",
    "# ---------- Second Subplot: Article Count per Data Channel----------\n",
    "sns.countplot(y='data_channel', data=df, order=sorted_channel, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Article Count per Data Channel')\n",
    "axes[0, 1].set_xlabel('Count')\n",
    "axes[0, 1].set_ylabel('Data Channel')\n",
    "\n",
    "# Annotate bars\n",
    "for p in axes[0, 1].patches:\n",
    "    axes[0, 1].annotate(format(p.get_width(), '.0f'),\n",
    "                        (p.get_width(), p.get_y() + p.get_height() / 2),\n",
    "                        ha='left', va='center',\n",
    "                        xytext=(5, 0),\n",
    "                        textcoords='offset points')\n",
    "\n",
    "# ---------- First Box Plot: Shares by Weekday ----------\n",
    "sns.boxplot(y='weekday', x='shares', data=df, order=sorted_day, ax=axes[1, 0], palette=\"Set2\")\n",
    "axes[1, 0].set_title('Shares by Weekday')\n",
    "axes[1, 0].set_xlabel('Shares')\n",
    "axes[1, 0].set_ylabel('Day of Week')\n",
    "\n",
    "# ---------- Second Box Plot: Shares by Data Channel ----------\n",
    "sns.boxplot(y='data_channel', x='shares', data=df, order=sorted_channel, ax=axes[1, 1], palette=\"Set2\")\n",
    "axes[1, 1].set_title('Shares by Data Channel')\n",
    "axes[1, 1].set_xlabel('Shares')\n",
    "axes[1, 1].set_ylabel('Data Channel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d42efe-1ca5-4b25-9128-0687378b68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ------- Scatter plot 1: Number of Images vs Shares, colored by Weekday --------\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='num_imgs', y='shares', data=df, hue='weekday', palette='Set2', alpha=0.7)\n",
    "plt.title('Scatter Plot: Number of Images vs Shares by Weekday')\n",
    "plt.xlabel('Number of Images')\n",
    "plt.ylabel('Shares')\n",
    "plt.legend(title='Weekday')\n",
    "plt.show()\n",
    "\n",
    "# ------- Scatter plot 2: Comments vs Shares, colored by Data Channel --------\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='n_comments', y='shares', data=df, hue='data_channel', palette='Set2', alpha=0.7)\n",
    "plt.title('Scatter Plot: Comments vs Shares by Data Channel')\n",
    "plt.xlabel('Number of Comments')\n",
    "plt.ylabel('Shares')\n",
    "plt.legend(title='Data Channel')\n",
    "plt.show()\n",
    "\n",
    "# ------- Scatter plot 3: Number of Videos vs Shares, colored by Data Channel ------\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='num_videos', y='shares', data=df, hue='data_channel', palette='Set2', alpha=0.7)\n",
    "plt.title('Scatter Plot: Number of Videos vs Shares by Data Channel')\n",
    "plt.xlabel('Number of Videos')\n",
    "plt.ylabel('Shares')\n",
    "plt.legend(title='Data Channel')\n",
    "plt.show()\n",
    "\n",
    "# ------- Scatter plot: Time Delta vs Shares, colored by Data Channel ------\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='timedelta', y='shares', data=df, hue='data_channel', palette='Set2', alpha=0.7)\n",
    "plt.title('Scatter Plot: Time Delta vs Shares by Data Channel')\n",
    "plt.xlabel('Time Delta')\n",
    "plt.ylabel('Shares')\n",
    "plt.legend(title='Data Channel')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e1bc8-3d36-4d55-8089-b28ae1d47edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ---------- Scenario A – Articles with low features but high shares ----------\n",
    "outliers = df[\n",
    "    (df['num_imgs'] == 0)  # No images\n",
    "    & (df['n_tokens_content'] < df['n_tokens_content'].quantile(0.25))  # Short articles\n",
    "    & (df['n_comments'] < df['n_comments'].quantile(0.25))  # Few comments\n",
    "    & (df['shares'] > df['shares'].quantile(0.9))  # Still highly shared\n",
    "]\n",
    "\n",
    "# Display stats for Scenario A\n",
    "outliers.describe().T\n",
    "# Goal: Find articles with unexpectedly high popularity despite lacking common \"success factors\". \n",
    "# Insight: High shares despite short length, no images, and few comments suggest the impact of strong headlines or timely relevance.\n",
    "\n",
    "# ---------- Scenario B – Viral Business Articles on Weekends ----------\n",
    "unusual_outliers = df[\n",
    "    (df['data_channel'] == 'Business') \n",
    "    & (df['weekday'].isin(['Saturday', 'Sunday'])) \n",
    "    & (df['shares'] > df['shares'].quantile(0.9))\n",
    "]\n",
    "\n",
    "# Display stats for Scenario B\n",
    "unusual_outliers.describe().T\n",
    "# Goal: Find which categories or weekdays produce \"viral despite odds\" articles.\n",
    "# Insight: Unusually high shares for weekend business articles hint at special events or changing reader habits influencing engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a680e70-cfa0-4ca7-b31d-cae171a8d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./mnt/data/mini_project_1_data.csv')\n",
    "df.head()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ---------- Low Attendance, High Performance [Male/Female] ----------\n",
    "# Filter the data for gender outliers\n",
    "outliers = df[\n",
    "    (df['gender'].isin(['Male', 'Female'])) \n",
    "    & (df['attendance_rate'] < 60) \n",
    "    & (df['final_test'] > 85)]\n",
    "\n",
    "# Display the gender outliers\n",
    "outliers\n",
    "# Insight: Exception cases where students perform well despite missing classes\n",
    "\n",
    "# Further filter the data for no-sibling outliers\n",
    "no_sibling_outliers = df[\n",
    "    (df['gender'].isin(['Male', 'Female']))\n",
    "    & (df['number_of_siblings'] == 0)]\n",
    "\n",
    "# Display the no-sibling outliers\n",
    "no_sibling_outliers.describe().T\n",
    "# Why: Find high-performing independent students who thrive despite not attending and having no siblings (fewer distractions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096d0eb-dda9-4547-8347-8789e9aed6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score, \n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from math import sqrt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/mnt/data/mini_project_1_data.csv') \n",
    "\n",
    "# Reset index after cleaning\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info(), df.head()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "df.describe().T\n",
    "\n",
    "# Check for duplicate entries\n",
    "df.duplicated().sum()\n",
    "duplicates = df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Basic cleanup\n",
    "df['high_share'] = (df['shares'] > df['shares'].median()).astype(int)\n",
    "df['weekday'] = df['weekday'].str.strip().str.lower().str.capitalize()\n",
    "df['data_channel'] = df['data_channel'].fillna('Unknown').str.strip().str.lower().str.replace('_', ' ').str.capitalize()\n",
    "\n",
    "# Prepare features\n",
    "x = df.drop(columns=['shares', 'ID', 'URL'])\n",
    "y = df['high_share']\n",
    "\n",
    "# Drop rows where any x value is missing\n",
    "x = x.copy()\n",
    "x = x.dropna()\n",
    "y = y.loc[x.index]  # Align y accordingly\n",
    "\n",
    "# Feature groups\n",
    "num_features = ['price', 'num_adults', 'num_children', 'arrival_day', 'checkout_day']\n",
    "cat_features = ['branch', 'platform', 'room', 'country', 'first_time']\n",
    "\n",
    "num_features = x.select_dtypes(include='number').columns.tolist()\n",
    "cat_features = x.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Preprocessor and pipeline setup\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "])\n",
    "\n",
    "# Retrieve feature names after preprocessing\n",
    "preprocessor.fit(x)\n",
    "feature_names = num_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(cat_features))\n",
    "\n",
    "# Pipelines\n",
    "cls_pipeline = Pipeline([('Preprocessor', preprocessor), ('Classification', LogisticRegression(max_iter=1000))])\n",
    "linear_pipeline = Pipeline([('Preprocessor', preprocessor), ('LinearRegression', LinearRegression())])\n",
    "ridge_pipeline = Pipeline([('Preprocessor', preprocessor), ('RidgeRegression', Ridge(alpha=1))])\n",
    "lasso_pipeline = Pipeline([('Preprocessor', preprocessor), ('LassoRegression', Lasso(alpha=1))])\n",
    "\n",
    "# Train-test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the models\n",
    "cls_pipeline.fit(x_train, y_train)\n",
    "linear_pipeline.fit(x_train, y_train)\n",
    "ridge_pipeline.fit(x_train, y_train)\n",
    "lasso_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cls = cls_pipeline.predict(x_test)\n",
    "y_pred_linear = linear_pipeline.predict(x_test)\n",
    "y_pred_ridge = ridge_pipeline.predict(x_test)\n",
    "y_pred_lasso = lasso_pipeline.predict(x_test)\n",
    "\n",
    "# Logistic Regression (Classification) metrics\n",
    "cls_metrics = {\n",
    "    \"Report\": classification_report(y_test, y_pred_cls, output_dict=True),\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_cls),\n",
    "    \"Precision\": precision_score(y_test, y_pred_cls),\n",
    "    \"Recall\": recall_score(y_test, y_pred_cls),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_cls)\n",
    "}\n",
    "\n",
    "\n",
    "# Grid search hyperparameter tuning\n",
    "param_grid_cls = {\n",
    "    'Classification__penalty': ['l2'], 'Classification__C': [0.1, 1, 10, 100, 1000],\n",
    "    'Classification__fit_intercept': [True, False], 'Classification__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'RidgeRegression__alpha': [0.1, 1, 10, 100, 1000], 'RidgeRegression__fit_intercept': [True, False],\n",
    "    'LassoRegression__alpha': [0.1, 1, 10, 100, 1000], 'LassoRegression__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "cls_grid = GridSearchCV(cls_pipeline, param_grid_cls, cv=5, scoring='accuracy')\n",
    "ridge_grid = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "lasso_grid = GridSearchCV(lasso_pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "cls_grid.fit(x_train, y_train)\n",
    "ridge_grid.fit(x_train, y_train)\n",
    "lasso_grid.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate Best Regression on test set\n",
    "best_cls = cls_grid.best_estimator_\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "\n",
    "# Evaluate Best Prediction\n",
    "y_pred_best_cls = best_cls.predict(x_test)\n",
    "y_pred_best_ridge = best_ridge.predict(x_test)\n",
    "y_pred_best_lasso = best_lasso.predict(x_test)\n",
    "\n",
    "print(\"Best Logistic (Classification) (GridSearchCV):\", cls_grid.best_params_)\n",
    "print(\"Best Ridge (GridSearchCV):\", ridge_grid.best_params_)\n",
    "print(\"Best Lasso (GridSearchCV):\", lasso_grid.best_params_)\n",
    "\n",
    "\n",
    "# Randomized Grid Search\n",
    "cls_random = RandomizedSearchCV(cls_pipeline, param_distributions=param_grid_cls, cv=5, scoring='accuracy')\n",
    "ridge_random = RandomizedSearchCV(ridge_pipeline, param_distributions=param_grid, n_iter=10, cv=5, scoring='r2', random_state=42, n_jobs=-1)\n",
    "lasso_random = RandomizedSearchCV(lasso_pipeline, param_distributions=param_grid, n_iter=10, cv=5, scoring='r2', random_state=42, n_jobs=-1)\n",
    "\n",
    "cls_random.fit(x_train, y_train)\n",
    "ridge_random.fit(x_train, y_train)\n",
    "lasso_random.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate Best Randomised Regression on test set\n",
    "bestRM_cls = cls_random.best_estimator_\n",
    "bestRM_ridge = ridge_random.best_estimator_\n",
    "bestRM_lasso = lasso_random.best_estimator_\n",
    "\n",
    "y_pred_bestRM_cls = bestRM_cls.predict(x_test)\n",
    "y_pred_bestRM_ridge = bestRM_ridge.predict(x_test)\n",
    "y_pred_bestRM_lasso = bestRM_lasso.predict(x_test)\n",
    "\n",
    "print(\"Best Logistic (Classification) (Randomized):\", cls_random.best_params_)\n",
    "print(\"Best Ridge (Randomized):\", ridge_random.best_params_)\n",
    "print(\"Best Lasso (Randomized):\", lasso_random.best_params_)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_cls(name, y_true, y_pred):\n",
    "    print(f\"{name} Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\\n\")\n",
    "\n",
    "def evaluate_reg(name, y_true, y_pred):\n",
    "    print(f\"{name} Regression Metrics:\")\n",
    "    print(f\"MAE:  {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"MSE:  {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"RMSE: {sqrt(mean_squared_error(y_true, y_pred)):.4f}\")\n",
    "    print(f\"R²:   {r2_score(y_true, y_pred):.4f}\\n\")\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_cls(\"Logistic\", y_test, y_pred_cls)\n",
    "\n",
    "print(\"------ Evaluation (Untuned) ------\")\n",
    "evaluate_reg(\"Ridge\", y_test, y_pred_ridge)\n",
    "evaluate_reg(\"Lasso\", y_test, y_pred_lasso)\n",
    "\n",
    "print(\"------ Best Evaluation (GridSearch) ------\")\n",
    "evaluate_reg(\"Best Ridge\", y_test, y_pred_best_ridge)\n",
    "evaluate_reg(\"Best Lasso\", y_test, y_pred_best_lasso)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_cls)\n",
    "\n",
    "# Coefficient\n",
    "cls_coefs = cls_pipeline.named_steps['Classification'].coef_.flatten()\n",
    "linear_coefs = linear_pipeline.named_steps['LinearRegression'].coef_\n",
    "ridge_coefs = ridge_pipeline.named_steps['RidgeRegression'].coef_\n",
    "lasso_coefs = lasso_pipeline.named_steps['LassoRegression'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Logistic [Classification]': cls_coefs,\n",
    "    'Linear Regression': linear_coefs,\n",
    "    'Ridge Regression': ridge_coefs,\n",
    "    'Lasso Regression': lasso_coefs\n",
    "}).melt(id_vars='Feature', var_name='Model', value_name='Coefficient').sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(data=coef_df, x='Feature', y='Coefficient', hue='Model', palette=['red', 'blue', 'green', 'yellow'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Regression (& Classification) Coefficients')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Final test set evaluation\n",
    "y_test_pred_linear = best_linear.predict(x_test)\n",
    "test_MAE_Linear = mean_absolute_error(y_test, y_test_pred_linear)\n",
    "test_MSE_Linear = mean_squared_error(y_test, y_test_pred_linear)\n",
    "test_RMSE_Linear = sqrt(mean_squared_error(y_test, y_test_pred_linear))\n",
    "test_R2_Linear = r2_score(y_test, y_test_pred_linear)\n",
    "\n",
    "y_test_pred_ridge = best_ridge.predict(x_test)\n",
    "test_MAE_Ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "test_MSE_Ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "test_RMSE_Ridge = sqrt(mean_squared_error(y_test, y_test_pred_ridge))\n",
    "test_R2_Ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "\n",
    "y_test_pred_lasso = best_lasso.predict(x_test)\n",
    "test_MAE_Lasso = mean_absolute_error(y_test, y_test_pred_lasso)\n",
    "test_MSE_Lasso = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "test_RMSE_Lasso = sqrt(mean_squared_error(y_test, y_test_pred_lasso))\n",
    "test_R2_Lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Linear Regression Report, Final Test Metrics:\")\n",
    "print(f\"Final Test MAE: {test_MAE_Linear:.4f}\")\n",
    "print(f\"Final Test MSE: {test_MSE_Linear:.4f}\")\n",
    "print(f\"Final Test RMSE: {test_RMSE_Linear:.4f}\")\n",
    "print(f\"Final Test R²: {test_R2_Linear:.4f}\")\n",
    "\n",
    "print(\"Best Ridge Regression Report, Final Test Metrics:\")\n",
    "print(f\"Final Test MAE: {test_MAE_Ridge:.4f}\")\n",
    "print(f\"Final Test MSE: {test_MSE_Ridge:.4f}\")\n",
    "print(f\"Final Test RMSE: {test_RMSE_Ridge:.4f}\")\n",
    "print(f\"Final Test R²: {test_R2_Ridge:.4f}\")\n",
    "\n",
    "print(\"Best Lasso Regression Report, Final Test Metrics:\")\n",
    "print(f\"Final Test MAE: {test_MAE_Lasso:.4f}\")\n",
    "print(f\"Final Test MSE: {test_MSE_Lasso:.4f}\")\n",
    "print(f\"Final Test RMSE: {test_RMSE_Lasso:.4f}\")\n",
    "print(f\"Final Test R²: {test_R2_Lasso:.4f}\")\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdbenv]",
   "language": "python",
   "name": "conda-env-hdbenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
